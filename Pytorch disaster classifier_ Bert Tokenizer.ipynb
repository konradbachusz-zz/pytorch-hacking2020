{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \n\nimport pandas as pd \npd.set_option('display.max_rows', 100)\npd.set_option('display.max_colwidth', 1000)\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n\nimport logging\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom transformers import *\n\nfrom nltk.tokenize import word_tokenize\n\nimport os\nimport re\nimport string\nimport random\nimport time\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 2020\nseed_everything(SEED)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_FILE_PATH = '/kaggle/input/nlp-getting-started/train.csv'\nTEST_FILE_PATH = '/kaggle/input/nlp-getting-started/test.csv'\nSUBMISSION_FILE_PATH = '/kaggle/input/nlp-getting-started/sample_submission.csv'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_FILE_PATH)\ntest_df = pd.read_csv(TEST_FILE_PATH)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Cleaning text data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\ntrain_df.at[train_df['id'].isin(ids_with_target_error),'target'] = 0\ntrain_df[train_df['id'].isin(ids_with_target_error)]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"        id             keyword                    location  \\\n229    328         annihilated                         NaN   \n301    443          apocalypse                         NaN   \n356    513                army                      Studio   \n1822  2619             crashed                         NaN   \n2536  3640          desolation               Quilmes , Arg   \n2715  3900          devastated                 PG Chillin!   \n3024  4342        dust%20storm                     chicago   \n4068  5781      forest%20fires                         NaN   \n4609  6552              injury                  Saint Paul   \n4611  6554              injury                         NaN   \n4622  6570              injury                         NaN   \n4713  6701                lava               Nashville, TN   \n4714  6702                lava  probably watching survivor   \n4732  6729                lava                 Clayton, NC   \n4820  6861       mass%20murder  i'm a Citizen of the World   \n5068  7226  natural%20disaster    on to the next adventure   \n\n                                                                                                                                               text  \\\n229                                                                                                      Ready to get annihilated for the BUCS game   \n301   Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ   \n356                                                But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.   \n1822                                                                             My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction   \n2536           This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away   \n2715                                Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....   \n3024                                                                   Going to a fest? Bring swimming goggles for the dust storm in the circle pit   \n4068     Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??   \n4609               My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game   \n4611                                                  Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U   \n4622                                                                                          @Sport_EN Just being linked to Arsenal causes injury.   \n4713                                                                                                 Imagine a room with walls that are lava lamps.   \n4714                             The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT   \n4732                                                                                        Check out my Lava lamp dude ???? http://t.co/To9ViqooFv   \n4820                                                         If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.   \n5068             Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!   \n\n      target  \n229        0  \n301        0  \n356        0  \n1822       0  \n2536       0  \n2715       0  \n3024       0  \n4068       0  \n4609       0  \n4611       0  \n4622       0  \n4713       0  \n4714       0  \n4732       0  \n4820       0  \n5068       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>229</th>\n      <td>328</td>\n      <td>annihilated</td>\n      <td>NaN</td>\n      <td>Ready to get annihilated for the BUCS game</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>443</td>\n      <td>apocalypse</td>\n      <td>NaN</td>\n      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the spirit the angel took me to the top of an enormous high mountain and... http://t.co/v8AfTD9zeZ</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>513</td>\n      <td>army</td>\n      <td>Studio</td>\n      <td>But if you build an army of 100 dogs and their leader is a lion all dogs will fight like a lion.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>2619</td>\n      <td>crashed</td>\n      <td>NaN</td>\n      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVHottest One Direction</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2536</th>\n      <td>3640</td>\n      <td>desolation</td>\n      <td>Quilmes , Arg</td>\n      <td>This desperation dislocation\\nSeparation condemnation\\nRevelation in temptation\\nIsolation desolation\\nLet it go and so to find away</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2715</th>\n      <td>3900</td>\n      <td>devastated</td>\n      <td>PG Chillin!</td>\n      <td>Man Currensy really be talkin that talk... I'd be more devastated if he had a ghostwriter than anybody else....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3024</th>\n      <td>4342</td>\n      <td>dust%20storm</td>\n      <td>chicago</td>\n      <td>Going to a fest? Bring swimming goggles for the dust storm in the circle pit</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4068</th>\n      <td>5781</td>\n      <td>forest%20fires</td>\n      <td>NaN</td>\n      <td>Campsite recommendations \\nToilets /shower \\nPub \\nFires \\nNo kids \\nPizza shop \\nForest \\nPretty stream \\nNo midges\\nNo snakes\\nThanks ??</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4609</th>\n      <td>6552</td>\n      <td>injury</td>\n      <td>Saint Paul</td>\n      <td>My prediction for the Vikings game this Sunday....dont expect a whole lot. Infact I think Zimmer goal is....injury free 1st game</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4611</th>\n      <td>6554</td>\n      <td>injury</td>\n      <td>NaN</td>\n      <td>Dante Exum's knee injury could stem Jazz's hoped-for surge back to ... http://t.co/8PIFutrB5U</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4622</th>\n      <td>6570</td>\n      <td>injury</td>\n      <td>NaN</td>\n      <td>@Sport_EN Just being linked to Arsenal causes injury.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4713</th>\n      <td>6701</td>\n      <td>lava</td>\n      <td>Nashville, TN</td>\n      <td>Imagine a room with walls that are lava lamps.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4714</th>\n      <td>6702</td>\n      <td>lava</td>\n      <td>probably watching survivor</td>\n      <td>The sunset looked like an erupting volcano .... My initial thought was the Pixar short Lava http://t.co/g4sChqFEsT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4732</th>\n      <td>6729</td>\n      <td>lava</td>\n      <td>Clayton, NC</td>\n      <td>Check out my Lava lamp dude ???? http://t.co/To9ViqooFv</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4820</th>\n      <td>6861</td>\n      <td>mass%20murder</td>\n      <td>i'm a Citizen of the World</td>\n      <td>If abortion is murder then blowjobs are cannibalism and masturbation is mass genocide.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5068</th>\n      <td>7226</td>\n      <td>natural%20disaster</td>\n      <td>on to the next adventure</td>\n      <td>Of course the one day I have to dress professionally aka unsensibly for class is the day I have try and outrun a natural disaster!</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_tweets(tweet):\n    \"\"\"Removes links and non-ASCII characters\"\"\"\n    \n    tweet = ''.join([x for x in tweet if x in string.printable])\n    \n    # Removing URLs\n    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n    \n    return tweet","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].apply(lambda x: clean_tweets(x))\ntest_df[\"text\"] = test_df[\"text\"].apply(lambda x: clean_tweets(x))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   id keyword location  \\\n0   1     NaN      NaN   \n1   4     NaN      NaN   \n2   5     NaN      NaN   \n3   6     NaN      NaN   \n4   7     NaN      NaN   \n\n                                                                                                                                    text  \\\n0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n1                                                                                                 Forest fire near La Ronge Sask. Canada   \n2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n3                                                                      13,000 people receive #wildfires evacuation orders in California    \n4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation orders in California</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].apply(lambda x: remove_emoji(x))\ntest_df[\"text\"] = test_df[\"text\"].apply(lambda x: remove_emoji(x))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuations(text):\n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n    \n    for p in punctuations:\n        text = text.replace(p, f' {p} ')\n\n    text = text.replace('...', ' ... ')\n    \n    if '...' not in text:\n        text = text.replace('..', ' ... ')\n    \n    return text","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].apply(lambda x: remove_punctuations(x))\ntest_df[\"text\"] = test_df[\"text\"].apply(lambda x: remove_punctuations(x))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abbreviations = {\n    \"$\" : \" dollar \",\n    \"â‚¬\" : \" euro \",\n    \"4ao\" : \"for adults only\",\n    \"a.m\" : \"before midday\",\n    \"a3\" : \"anytime anywhere anyplace\",\n    \"aamof\" : \"as a matter of fact\",\n    \"acct\" : \"account\",\n    \"adih\" : \"another day in hell\",\n    \"afaic\" : \"as far as i am concerned\",\n    \"afaict\" : \"as far as i can tell\",\n    \"afaik\" : \"as far as i know\",\n    \"afair\" : \"as far as i remember\",\n    \"afk\" : \"away from keyboard\",\n    \"app\" : \"application\",\n    \"approx\" : \"approximately\",\n    \"apps\" : \"applications\",\n    \"asap\" : \"as soon as possible\",\n    \"asl\" : \"age, sex, location\",\n    \"atk\" : \"at the keyboard\",\n    \"ave.\" : \"avenue\",\n    \"aymm\" : \"are you my mother\",\n    \"ayor\" : \"at your own risk\", \n    \"b&b\" : \"bed and breakfast\",\n    \"b+b\" : \"bed and breakfast\",\n    \"b.c\" : \"before christ\",\n    \"b2b\" : \"business to business\",\n    \"b2c\" : \"business to customer\",\n    \"b4\" : \"before\",\n    \"b4n\" : \"bye for now\",\n    \"b@u\" : \"back at you\",\n    \"bae\" : \"before anyone else\",\n    \"bak\" : \"back at keyboard\",\n    \"bbbg\" : \"bye bye be good\",\n    \"bbc\" : \"british broadcasting corporation\",\n    \"bbias\" : \"be back in a second\",\n    \"bbl\" : \"be back later\",\n    \"bbs\" : \"be back soon\",\n    \"be4\" : \"before\",\n    \"bfn\" : \"bye for now\",\n    \"blvd\" : \"boulevard\",\n    \"bout\" : \"about\",\n    \"brb\" : \"be right back\",\n    \"bros\" : \"brothers\",\n    \"brt\" : \"be right there\",\n    \"bsaaw\" : \"big smile and a wink\",\n    \"btw\" : \"by the way\",\n    \"bwl\" : \"bursting with laughter\",\n    \"c/o\" : \"care of\",\n    \"cet\" : \"central european time\",\n    \"cf\" : \"compare\",\n    \"cia\" : \"central intelligence agency\",\n    \"csl\" : \"can not stop laughing\",\n    \"cu\" : \"see you\",\n    \"cul8r\" : \"see you later\",\n    \"cv\" : \"curriculum vitae\",\n    \"cwot\" : \"complete waste of time\",\n    \"cya\" : \"see you\",\n    \"cyt\" : \"see you tomorrow\",\n    \"dae\" : \"does anyone else\",\n    \"dbmib\" : \"do not bother me i am busy\",\n    \"diy\" : \"do it yourself\",\n    \"dm\" : \"direct message\",\n    \"dwh\" : \"during work hours\",\n    \"e123\" : \"easy as one two three\",\n    \"eet\" : \"eastern european time\",\n    \"eg\" : \"example\",\n    \"embm\" : \"early morning business meeting\",\n    \"encl\" : \"enclosed\",\n    \"encl.\" : \"enclosed\",\n    \"etc\" : \"and so on\",\n    \"faq\" : \"frequently asked questions\",\n    \"fawc\" : \"for anyone who cares\",\n    \"fb\" : \"facebook\",\n    \"fc\" : \"fingers crossed\",\n    \"fig\" : \"figure\",\n    \"fimh\" : \"forever in my heart\", \n    \"ft.\" : \"feet\",\n    \"ft\" : \"featuring\",\n    \"ftl\" : \"for the loss\",\n    \"ftw\" : \"for the win\",\n    \"fwiw\" : \"for what it is worth\",\n    \"fyi\" : \"for your information\",\n    \"g9\" : \"genius\",\n    \"gahoy\" : \"get a hold of yourself\",\n    \"gal\" : \"get a life\",\n    \"gcse\" : \"general certificate of secondary education\",\n    \"gfn\" : \"gone for now\",\n    \"gg\" : \"good game\",\n    \"gl\" : \"good luck\",\n    \"glhf\" : \"good luck have fun\",\n    \"gmt\" : \"greenwich mean time\",\n    \"gmta\" : \"great minds think alike\",\n    \"gn\" : \"good night\",\n    \"g.o.a.t\" : \"greatest of all time\",\n    \"goat\" : \"greatest of all time\",\n    \"goi\" : \"get over it\",\n    \"gps\" : \"global positioning system\",\n    \"gr8\" : \"great\",\n    \"gratz\" : \"congratulations\",\n    \"gyal\" : \"girl\",\n    \"h&c\" : \"hot and cold\",\n    \"hp\" : \"horsepower\",\n    \"hr\" : \"hour\",\n    \"hrh\" : \"his royal highness\",\n    \"ht\" : \"height\",\n    \"ibrb\" : \"i will be right back\",\n    \"ic\" : \"i see\",\n    \"icq\" : \"i seek you\",\n    \"icymi\" : \"in case you missed it\",\n    \"idc\" : \"i do not care\",\n    \"idgadf\" : \"i do not give a damn fuck\",\n    \"idgaf\" : \"i do not give a fuck\",\n    \"idk\" : \"i do not know\",\n    \"ie\" : \"that is\",\n    \"i.e\" : \"that is\",\n    \"ifyp\" : \"i feel your pain\",\n    \"IG\" : \"instagram\",\n    \"iirc\" : \"if i remember correctly\",\n    \"ilu\" : \"i love you\",\n    \"ily\" : \"i love you\",\n    \"imho\" : \"in my humble opinion\",\n    \"imo\" : \"in my opinion\",\n    \"imu\" : \"i miss you\",\n    \"iow\" : \"in other words\",\n    \"irl\" : \"in real life\",\n    \"j4f\" : \"just for fun\",\n    \"jic\" : \"just in case\",\n    \"jk\" : \"just kidding\",\n    \"jsyk\" : \"just so you know\",\n    \"l8r\" : \"later\",\n    \"lb\" : \"pound\",\n    \"lbs\" : \"pounds\",\n    \"ldr\" : \"long distance relationship\",\n    \"lmao\" : \"laugh my ass off\",\n    \"lmfao\" : \"laugh my fucking ass off\",\n    \"lol\" : \"laughing out loud\",\n    \"ltd\" : \"limited\",\n    \"ltns\" : \"long time no see\",\n    \"m8\" : \"mate\",\n    \"mf\" : \"motherfucker\",\n    \"mfs\" : \"motherfuckers\",\n    \"mfw\" : \"my face when\",\n    \"mofo\" : \"motherfucker\",\n    \"mph\" : \"miles per hour\",\n    \"mr\" : \"mister\",\n    \"mrw\" : \"my reaction when\",\n    \"ms\" : \"miss\",\n    \"mte\" : \"my thoughts exactly\",\n    \"nagi\" : \"not a good idea\",\n    \"nbc\" : \"national broadcasting company\",\n    \"nbd\" : \"not big deal\",\n    \"nfs\" : \"not for sale\",\n    \"ngl\" : \"not going to lie\",\n    \"nhs\" : \"national health service\",\n    \"nrn\" : \"no reply necessary\",\n    \"nsfl\" : \"not safe for life\",\n    \"nsfw\" : \"not safe for work\",\n    \"nth\" : \"nice to have\",\n    \"nvr\" : \"never\",\n    \"nyc\" : \"new york city\",\n    \"oc\" : \"original content\",\n    \"og\" : \"original\",\n    \"ohp\" : \"overhead projector\",\n    \"oic\" : \"oh i see\",\n    \"omdb\" : \"over my dead body\",\n    \"omg\" : \"oh my god\",\n    \"omw\" : \"on my way\",\n    \"p.a\" : \"per annum\",\n    \"p.m\" : \"after midday\",\n    \"pm\" : \"prime minister\",\n    \"poc\" : \"people of color\",\n    \"pov\" : \"point of view\",\n    \"pp\" : \"pages\",\n    \"ppl\" : \"people\",\n    \"prw\" : \"parents are watching\",\n    \"ps\" : \"postscript\",\n    \"pt\" : \"point\",\n    \"ptb\" : \"please text back\",\n    \"pto\" : \"please turn over\",\n    \"qpsa\" : \"what happens\", #\"que pasa\",\n    \"ratchet\" : \"rude\",\n    \"rbtl\" : \"read between the lines\",\n    \"rlrt\" : \"real life retweet\", \n    \"rofl\" : \"rolling on the floor laughing\",\n    \"roflol\" : \"rolling on the floor laughing out loud\",\n    \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n    \"rt\" : \"retweet\",\n    \"ruok\" : \"are you ok\",\n    \"sfw\" : \"safe for work\",\n    \"sk8\" : \"skate\",\n    \"smh\" : \"shake my head\",\n    \"sq\" : \"square\",\n    \"srsly\" : \"seriously\", \n    \"ssdd\" : \"same stuff different day\",\n    \"tbh\" : \"to be honest\",\n    \"tbs\" : \"tablespooful\",\n    \"tbsp\" : \"tablespooful\",\n    \"tfw\" : \"that feeling when\",\n    \"thks\" : \"thank you\",\n    \"tho\" : \"though\",\n    \"thx\" : \"thank you\",\n    \"tia\" : \"thanks in advance\",\n    \"til\" : \"today i learned\",\n    \"tl;dr\" : \"too long i did not read\",\n    \"tldr\" : \"too long i did not read\",\n    \"tmb\" : \"tweet me back\",\n    \"tntl\" : \"trying not to laugh\",\n    \"ttyl\" : \"talk to you later\",\n    \"u\" : \"you\",\n    \"u2\" : \"you too\",\n    \"u4e\" : \"yours for ever\",\n    \"utc\" : \"coordinated universal time\",\n    \"w/\" : \"with\",\n    \"w/o\" : \"without\",\n    \"w8\" : \"wait\",\n    \"wassup\" : \"what is up\",\n    \"wb\" : \"welcome back\",\n    \"wtf\" : \"what the fuck\",\n    \"wtg\" : \"way to go\",\n    \"wtpa\" : \"where the party at\",\n    \"wuf\" : \"where are you from\",\n    \"wuzup\" : \"what is up\",\n    \"wywh\" : \"wish you were here\",\n    \"yd\" : \"yard\",\n    \"ygtr\" : \"you got that right\",\n    \"ynk\" : \"you never know\",\n    \"zzz\" : \"sleeping bored and tired\"\n}","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_abbrev(word):\n    return abbreviations[word.lower()] if word.lower() in abbreviations.keys() else word","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_abbrev_in_text(text):\n    tokens = word_tokenize(text)\n    tokens = [convert_abbrev(word) for word in tokens]\n    text = ' '.join(tokens)\n    return text","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"text\"] = train_df[\"text\"].apply(lambda x: convert_abbrev_in_text(x))\ntest_df[\"text\"] = test_df[\"text\"].apply(lambda x: convert_abbrev_in_text(x))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove stopwords\nfrom nltk.corpus import stopwords\n\nimport nltk\nimport regex as re\n\n#remove stop words \nstop = stopwords.words('english')\ntrain_df['text']=train_df['text'].str.lower().apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\ntest_df['text']=test_df['text'].str.lower().apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lemmatize\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\ndef lemmatize_text(text):\n    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n\n#lemmatization\ntrain_df['text'] = train_df['text'].apply(lemmatize_text)\ntrain_df['text']=[' '.join(map(str, l)) for l in train_df['text']]\ntest_df['text'] = test_df['text'].apply(lemmatize_text)\ntest_df['text']=[' '.join(map(str, l)) for l in test_df['text']]\n\n#replace numbers with string\ntrain_df['text']=train_df['text'].str.replace('\\d+', '')\ntest_df['text']=test_df['text'].str.replace('\\d+', '')\n\n#removing https\ntrain_df['text']=train_df['text'].str.replace('https?://\\\\S+|www\\\\.\\\\S+', '')\ntrain_df['text']=train_df['text'].str.replace('http?://\\\\S+|www\\\\.\\\\S+', '')\n\ntest_df['text']=test_df['text'].str.replace('https?://\\\\S+|www\\\\.\\\\S+', '')\ntest_df['text']=test_df['text'].str.replace('http?://\\\\S+|www\\\\.\\\\S+', '')\n\n#Remove HTML tags\n\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\n\ntrain_df['text']=train_df['text'].apply(lambda x : remove_html(x))\ntest_df['text']=test_df['text'].apply(lambda x : remove_html(x))\n\n#removing usernames\ntrain_df['text']=train_df['text'].str.replace('_+\\\\w*', 'username')\ntest_df['text']=test_df['text'].str.replace('_+\\\\w*', 'username')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"7613"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"<h2>Modelling</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class InputExample(object):\n    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n\n    def __init__(self, id, text, label=None):\n        \"\"\"Constructs a InputExample.\n        Args:\n            id: Unique id for the example.\n            text: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"\n        self.id = id\n        self.text = text\n        self.label = label\n\n\nclass InputFeatures(object):\n    def __init__(self, example_id, choices_features, label):\n        \n        self.example_id = example_id\n        _, input_ids, input_mask, segment_ids = choices_features[0]\n        self.choices_features = {\n            'input_ids': input_ids,\n            'input_mask': input_mask,\n            'segment_ids': segment_ids\n        }\n        self.label = label","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_examples(df, is_training):\n    if not is_training:\n        df['target'] = np.zeros(len(df), dtype=np.int64)\n    examples = []\n    for val in df[['id', 'text', 'target']].values:\n        examples.append(InputExample(id=val[0], text=val[1], label=val[2]))\n    return examples, df\n\ndef _truncate_seq_pair(tokens_a, tokens_b, max_length):\n    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n\n    # This is a simple heuristic which will always truncate the longer sequence\n    # one token at a time. This makes more sense than truncating an equal percent\n    # of tokens from each, since if one sequence is very short then each token\n    # that's truncated likely contains more information than a longer sequence.\n\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_length:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop()\n        else:\n            tokens_b.pop()","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_examples_to_features(examples, tokenizer, max_seq_length, is_training):\n    \n    features = []\n    \n    for example_index, example in enumerate(examples):\n        \n        text = tokenizer.tokenize(example.text)\n        MAX_TEXT_LEN = max_seq_length - 2 \n        text = text[:MAX_TEXT_LEN]\n\n        choices_features = []\n\n        tokens = [\"[CLS]\"] + text + [\"[SEP]\"]  \n        segment_ids = [0] * (len(text) + 2) \n        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n        input_mask = [1] * len(input_ids)\n\n        padding_length = max_seq_length - len(input_ids)\n        input_ids += ([0] * padding_length)\n        input_mask += ([0] * padding_length)\n        segment_ids += ([0] * padding_length)\n        choices_features.append((tokens, input_ids, input_mask, segment_ids))\n\n        label = example.label\n        if example_index < 1 and is_training:\n            logger.info(\"*** Example ***\")\n            logger.info(\"idx: {}\".format(example_index))\n            logger.info(\"id: {}\".format(example.id))\n            logger.info(\"tokens: {}\".format(' '.join(tokens).replace('\\u2581', '_')))\n            logger.info(\"input_ids: {}\".format(' '.join(map(str, input_ids))))\n            logger.info(\"input_mask: {}\".format(len(input_mask)))\n            logger.info(\"segment_ids: {}\".format(len(segment_ids)))\n            logger.info(\"label: {}\".format(label))\n\n        features.append(\n            InputFeatures(\n                example_id=example.id,\n                choices_features=choices_features,\n                label=label\n            )\n        )\n    return features","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_field(features, field):\n    return [feature.choices_features[field] for feature in features]","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    return acc, f1","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\n\nMAX_SEQ_LENGTH = 512  \nLEARNING_RATE = 1e-5  \nNUM_EPOCHS = 3  \nBATCH_SIZE = 8  \nPATIENCE = 2  \nFILE_NAME = 'model' \nNUM_FOLDS = 5","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = logging.getLogger('mylogger')\nlogger.setLevel(logging.DEBUG)\n\ntimestamp = time.strftime(\"%Y.%m.%d_%H.%M.%S\", time.localtime())\n\nfh = logging.FileHandler('log_model.txt')\nfh.setLevel(logging.DEBUG)\n\nch = logging.StreamHandler()\nch.setLevel(logging.DEBUG)\n\nformatter = logging.Formatter('[%(asctime)s][%(levelname)s] ## %(message)s')\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n\nlogger.addHandler(fh)\nlogger.addHandler(ch)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_dataloaders(df):\n    examples, df = read_examples(df, is_training=True)\n    \n    labels = df[\"target\"].astype(int).values\n    \n    features = convert_examples_to_features(examples, tokenizer, MAX_SEQ_LENGTH, True)\n    input_ids = torch.tensor(select_field(features, 'input_ids'))\n    input_mask = torch.tensor(select_field(features, 'input_mask'))\n    segment_ids = torch.tensor(select_field(features, 'segment_ids'))\n    label = torch.tensor([f.label for f in features])\n    \n    dataset = torch.utils.data.TensorDataset(input_ids, input_mask, segment_ids, label)\n    data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n    \n    return data_loader, labels","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, hidden_size=768, num_classes=2):\n        super(NeuralNet, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True, output_attentions=True)\n\n        for param in self.bert.parameters():\n            param.requires_grad = True\n        \n        self.drop_out = nn.Dropout() # dropout layer to prevent overfitting\n        self.fc = nn.Linear(hidden_size, num_classes) # fully connected layer\n        \n    def forward(self, input_ids, input_mask, segment_ids):\n        last_hidden_state, pooler_output, all_hidden_states, all_attentions = self.bert(input_ids, token_type_ids = segment_ids, attention_mask = input_mask)\n        last_hidden_state = last_hidden_state[:, 0,:]                                                       \n        \n        # Linear layer expects a tensor of size [batch size, input size]\n        out = self.drop_out(last_hidden_state) \n        out = self.fc(out) \n        return F.log_softmax(out)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(NUM_FOLDS, shuffle=True, random_state=SEED)\nnfold = 1\n\nfor train_index, valid_index in skf.split(train_df[\"text\"], train_df[\"target\"]):\n    train = train_df.iloc[train_index, :]\n    valid = train_df.iloc[valid_index, :]\n    \n    train_loader, train_labels = generate_dataloaders(train)\n    valid_loader, valid_labels = generate_dataloaders(valid)\n    \n    model = NeuralNet()\n    model.cuda()\n    \n    # Training model on 4 fold\n    model.train()\n    \n    loss_fn = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    total_step = len(train_loader)\n    \n    for epoch in range(NUM_EPOCHS):\n        train_loss = 0.\n        \n        # Training loop\n        for i, batch in enumerate(train_loader):\n            batch = tuple(t.cuda() for t in batch)\n            x_ids, x_mask, x_sids, y_truth = batch\n            y_pred = model(x_ids, x_mask, x_sids)\n            loss = loss_fn(y_pred, y_truth)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() / len(train_loader)\n            \n            total = len(y_truth)\n            _, predicted = torch.max(y_pred.data, 1)\n            correct = (predicted == y_truth).sum().item()\n            \n            if (i + 1) % 50 == 0:\n                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch + 1, NUM_EPOCHS, i + 1, total_step, loss.item(), (correct / total) * 100)) \n        \n    # Validating model performance on the remaining fold\n    model.eval()\n    \n    with torch.no_grad():\n        correct, total = 0, 0\n        \n        for i, batch in enumerate(valid_loader):\n            batch = tuple(t.cuda() for t in batch)\n            x_ids, x_mask, x_sids, y_truth = batch\n            y_pred = model(x_ids, x_mask, x_sids)\n            _, predicted = torch.max(y_pred.data, 1)\n            total += len(valid_labels)\n            correct += (predicted == y_truth).sum().item()\n            \n        print('Validation performance on {}-th fold: {}'.format(nfold, (correct / total) * 100))\n    \n    nfold += 1\n    models.append(model)","execution_count":30,"outputs":[{"output_type":"stream","text":"[2020-03-03 19:00:17,864][INFO] ## *** Example ***\n[2020-03-03 19:00:17,864][INFO] ## idx: 0\n[2020-03-03 19:00:17,866][INFO] ## id: 1\n[2020-03-03 19:00:17,868][INFO] ## tokens: [CLS] our deeds are the reason of this # earthquake may allah forgive us all [SEP]\n[2020-03-03 19:00:17,869][INFO] ## input_ids: 101 2256 15616 2024 1996 3114 1997 2023 1001 8372 2089 16455 9641 2149 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:00:17,870][INFO] ## input_mask: 512\n[2020-03-03 19:00:17,871][INFO] ## segment_ids: 512\n[2020-03-03 19:00:17,872][INFO] ## label: 1\n[2020-03-03 19:00:23,890][INFO] ## *** Example ***\n[2020-03-03 19:00:23,892][INFO] ## idx: 0\n[2020-03-03 19:00:23,894][INFO] ## id: 10\n[2020-03-03 19:00:23,895][INFO] ## tokens: [CLS] # flood # disaster heavy rain causes flash flooding of streets in mani ##tou , colorado springs areas [SEP]\n[2020-03-03 19:00:23,897][INFO] ## input_ids: 101 1001 7186 1001 7071 3082 4542 5320 5956 9451 1997 4534 1999 23624 24826 1010 5169 6076 2752 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:00:23,900][INFO] ## input_mask: 512\n[2020-03-03 19:00:23,903][INFO] ## segment_ids: 512\n[2020-03-03 19:00:23,905][INFO] ## label: 1\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"Epoch [1/3], Step [50/762], Loss: 0.4895, Accuracy: 87.50%\nEpoch [1/3], Step [100/762], Loss: 0.6353, Accuracy: 62.50%\nEpoch [1/3], Step [150/762], Loss: 1.0194, Accuracy: 62.50%\nEpoch [1/3], Step [200/762], Loss: 0.7062, Accuracy: 62.50%\nEpoch [1/3], Step [250/762], Loss: 0.2952, Accuracy: 87.50%\nEpoch [1/3], Step [300/762], Loss: 0.3858, Accuracy: 87.50%\nEpoch [1/3], Step [350/762], Loss: 0.3723, Accuracy: 87.50%\nEpoch [1/3], Step [400/762], Loss: 0.3550, Accuracy: 75.00%\nEpoch [1/3], Step [450/762], Loss: 0.5191, Accuracy: 87.50%\nEpoch [1/3], Step [500/762], Loss: 0.3180, Accuracy: 87.50%\nEpoch [1/3], Step [550/762], Loss: 0.7056, Accuracy: 75.00%\nEpoch [1/3], Step [600/762], Loss: 0.1736, Accuracy: 87.50%\nEpoch [1/3], Step [650/762], Loss: 0.6912, Accuracy: 75.00%\nEpoch [1/3], Step [700/762], Loss: 0.9027, Accuracy: 62.50%\nEpoch [1/3], Step [750/762], Loss: 0.2091, Accuracy: 87.50%\nEpoch [2/3], Step [50/762], Loss: 0.0922, Accuracy: 100.00%\nEpoch [2/3], Step [100/762], Loss: 0.3355, Accuracy: 87.50%\nEpoch [2/3], Step [150/762], Loss: 0.2728, Accuracy: 87.50%\nEpoch [2/3], Step [200/762], Loss: 0.9491, Accuracy: 50.00%\nEpoch [2/3], Step [250/762], Loss: 0.2703, Accuracy: 87.50%\nEpoch [2/3], Step [300/762], Loss: 0.2816, Accuracy: 87.50%\nEpoch [2/3], Step [350/762], Loss: 0.5137, Accuracy: 62.50%\nEpoch [2/3], Step [400/762], Loss: 0.1924, Accuracy: 87.50%\nEpoch [2/3], Step [450/762], Loss: 0.0590, Accuracy: 100.00%\nEpoch [2/3], Step [500/762], Loss: 0.1937, Accuracy: 87.50%\nEpoch [2/3], Step [550/762], Loss: 0.1729, Accuracy: 87.50%\nEpoch [2/3], Step [600/762], Loss: 0.5297, Accuracy: 62.50%\nEpoch [2/3], Step [650/762], Loss: 0.0723, Accuracy: 100.00%\nEpoch [2/3], Step [700/762], Loss: 0.3172, Accuracy: 87.50%\nEpoch [2/3], Step [750/762], Loss: 0.3780, Accuracy: 75.00%\nEpoch [3/3], Step [50/762], Loss: 0.1275, Accuracy: 100.00%\nEpoch [3/3], Step [100/762], Loss: 0.0215, Accuracy: 100.00%\nEpoch [3/3], Step [150/762], Loss: 0.3946, Accuracy: 75.00%\nEpoch [3/3], Step [200/762], Loss: 0.0607, Accuracy: 100.00%\nEpoch [3/3], Step [250/762], Loss: 0.0911, Accuracy: 100.00%\nEpoch [3/3], Step [300/762], Loss: 0.4706, Accuracy: 87.50%\nEpoch [3/3], Step [350/762], Loss: 0.0552, Accuracy: 100.00%\nEpoch [3/3], Step [400/762], Loss: 0.0990, Accuracy: 100.00%\nEpoch [3/3], Step [450/762], Loss: 0.0407, Accuracy: 100.00%\nEpoch [3/3], Step [500/762], Loss: 0.1279, Accuracy: 87.50%\nEpoch [3/3], Step [550/762], Loss: 0.2009, Accuracy: 87.50%\nEpoch [3/3], Step [600/762], Loss: 0.1571, Accuracy: 87.50%\nEpoch [3/3], Step [650/762], Loss: 0.5640, Accuracy: 87.50%\nEpoch [3/3], Step [700/762], Loss: 0.2517, Accuracy: 87.50%\nEpoch [3/3], Step [750/762], Loss: 0.0744, Accuracy: 100.00%\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:19:02,074][INFO] ## *** Example ***\n[2020-03-03 19:19:02,075][INFO] ## idx: 0\n[2020-03-03 19:19:02,077][INFO] ## id: 1\n[2020-03-03 19:19:02,078][INFO] ## tokens: [CLS] our deeds are the reason of this # earthquake may allah forgive us all [SEP]\n[2020-03-03 19:19:02,081][INFO] ## input_ids: 101 2256 15616 2024 1996 3114 1997 2023 1001 8372 2089 16455 9641 2149 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:19:02,083][INFO] ## input_mask: 512\n[2020-03-03 19:19:02,085][INFO] ## segment_ids: 512\n[2020-03-03 19:19:02,086][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Validation performance on 1-th fold: 0.44414956702292596\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:19:07,491][INFO] ## *** Example ***\n[2020-03-03 19:19:07,492][INFO] ## idx: 0\n[2020-03-03 19:19:07,493][INFO] ## id: 4\n[2020-03-03 19:19:07,496][INFO] ## tokens: [CLS] forest fire near la ron ##ge sas ##k . canada [SEP]\n[2020-03-03 19:19:07,498][INFO] ## input_ids: 101 3224 2543 2379 2474 6902 3351 21871 2243 1012 2710 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:19:07,499][INFO] ## input_mask: 512\n[2020-03-03 19:19:07,500][INFO] ## segment_ids: 512\n[2020-03-03 19:19:07,504][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Epoch [1/3], Step [50/762], Loss: 0.7899, Accuracy: 37.50%\nEpoch [1/3], Step [100/762], Loss: 0.6061, Accuracy: 75.00%\nEpoch [1/3], Step [150/762], Loss: 0.5039, Accuracy: 75.00%\nEpoch [1/3], Step [200/762], Loss: 0.5055, Accuracy: 75.00%\nEpoch [1/3], Step [250/762], Loss: 0.5999, Accuracy: 75.00%\nEpoch [1/3], Step [300/762], Loss: 0.2817, Accuracy: 100.00%\nEpoch [1/3], Step [350/762], Loss: 0.2373, Accuracy: 100.00%\nEpoch [1/3], Step [400/762], Loss: 0.5950, Accuracy: 75.00%\nEpoch [1/3], Step [450/762], Loss: 0.5043, Accuracy: 75.00%\nEpoch [1/3], Step [500/762], Loss: 0.1789, Accuracy: 100.00%\nEpoch [1/3], Step [550/762], Loss: 0.1630, Accuracy: 100.00%\nEpoch [1/3], Step [600/762], Loss: 0.1074, Accuracy: 100.00%\nEpoch [1/3], Step [650/762], Loss: 0.4853, Accuracy: 75.00%\nEpoch [1/3], Step [700/762], Loss: 0.2366, Accuracy: 100.00%\nEpoch [1/3], Step [750/762], Loss: 0.2839, Accuracy: 87.50%\nEpoch [2/3], Step [50/762], Loss: 0.1839, Accuracy: 87.50%\nEpoch [2/3], Step [100/762], Loss: 0.0716, Accuracy: 100.00%\nEpoch [2/3], Step [150/762], Loss: 0.3735, Accuracy: 87.50%\nEpoch [2/3], Step [200/762], Loss: 0.5810, Accuracy: 62.50%\nEpoch [2/3], Step [250/762], Loss: 0.1779, Accuracy: 100.00%\nEpoch [2/3], Step [300/762], Loss: 0.7670, Accuracy: 75.00%\nEpoch [2/3], Step [350/762], Loss: 0.5107, Accuracy: 87.50%\nEpoch [2/3], Step [400/762], Loss: 0.6275, Accuracy: 75.00%\nEpoch [2/3], Step [450/762], Loss: 0.4212, Accuracy: 87.50%\nEpoch [2/3], Step [500/762], Loss: 0.0760, Accuracy: 100.00%\nEpoch [2/3], Step [550/762], Loss: 0.7215, Accuracy: 50.00%\nEpoch [2/3], Step [600/762], Loss: 0.2066, Accuracy: 100.00%\nEpoch [2/3], Step [650/762], Loss: 0.4496, Accuracy: 87.50%\nEpoch [2/3], Step [700/762], Loss: 0.0745, Accuracy: 100.00%\nEpoch [2/3], Step [750/762], Loss: 0.1231, Accuracy: 100.00%\nEpoch [3/3], Step [50/762], Loss: 0.0954, Accuracy: 100.00%\nEpoch [3/3], Step [100/762], Loss: 0.2034, Accuracy: 87.50%\nEpoch [3/3], Step [150/762], Loss: 0.0804, Accuracy: 100.00%\nEpoch [3/3], Step [200/762], Loss: 0.3453, Accuracy: 75.00%\nEpoch [3/3], Step [250/762], Loss: 0.0360, Accuracy: 100.00%\nEpoch [3/3], Step [300/762], Loss: 0.3757, Accuracy: 75.00%\nEpoch [3/3], Step [350/762], Loss: 0.1072, Accuracy: 100.00%\nEpoch [3/3], Step [400/762], Loss: 0.3615, Accuracy: 87.50%\nEpoch [3/3], Step [450/762], Loss: 0.1377, Accuracy: 100.00%\nEpoch [3/3], Step [500/762], Loss: 0.4632, Accuracy: 87.50%\nEpoch [3/3], Step [550/762], Loss: 0.3221, Accuracy: 75.00%\nEpoch [3/3], Step [600/762], Loss: 0.0741, Accuracy: 100.00%\nEpoch [3/3], Step [650/762], Loss: 0.0625, Accuracy: 100.00%\nEpoch [3/3], Step [700/762], Loss: 0.2321, Accuracy: 87.50%\nEpoch [3/3], Step [750/762], Loss: 0.1969, Accuracy: 87.50%\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:37:26,261][INFO] ## *** Example ***\n[2020-03-03 19:37:26,263][INFO] ## idx: 0\n[2020-03-03 19:37:26,264][INFO] ## id: 1\n[2020-03-03 19:37:26,268][INFO] ## tokens: [CLS] our deeds are the reason of this # earthquake may allah forgive us all [SEP]\n[2020-03-03 19:37:26,270][INFO] ## input_ids: 101 2256 15616 2024 1996 3114 1997 2023 1001 8372 2089 16455 9641 2149 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:37:26,271][INFO] ## input_mask: 512\n[2020-03-03 19:37:26,272][INFO] ## segment_ids: 512\n[2020-03-03 19:37:26,275][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Validation performance on 2-th fold: 0.43658664869900615\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:37:32,051][INFO] ## *** Example ***\n[2020-03-03 19:37:32,052][INFO] ## idx: 0\n[2020-03-03 19:37:32,055][INFO] ## id: 6\n[2020-03-03 19:37:32,056][INFO] ## tokens: [CLS] 13 , 000 people receive # wild ##fires evacuation orders in california [SEP]\n[2020-03-03 19:37:32,058][INFO] ## input_ids: 101 2410 1010 2199 2111 4374 1001 3748 26332 13982 4449 1999 2662 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:37:32,062][INFO] ## input_mask: 512\n[2020-03-03 19:37:32,063][INFO] ## segment_ids: 512\n[2020-03-03 19:37:32,063][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Epoch [1/3], Step [50/762], Loss: 0.6573, Accuracy: 62.50%\nEpoch [1/3], Step [100/762], Loss: 0.3416, Accuracy: 75.00%\nEpoch [1/3], Step [150/762], Loss: 0.4128, Accuracy: 87.50%\nEpoch [1/3], Step [200/762], Loss: 1.1464, Accuracy: 37.50%\nEpoch [1/3], Step [250/762], Loss: 0.1500, Accuracy: 100.00%\nEpoch [1/3], Step [300/762], Loss: 0.2779, Accuracy: 100.00%\nEpoch [1/3], Step [350/762], Loss: 0.2765, Accuracy: 87.50%\nEpoch [1/3], Step [400/762], Loss: 0.1751, Accuracy: 100.00%\nEpoch [1/3], Step [450/762], Loss: 0.4837, Accuracy: 75.00%\nEpoch [1/3], Step [500/762], Loss: 0.4274, Accuracy: 75.00%\nEpoch [1/3], Step [550/762], Loss: 0.5969, Accuracy: 87.50%\nEpoch [1/3], Step [600/762], Loss: 0.5390, Accuracy: 75.00%\nEpoch [1/3], Step [650/762], Loss: 0.3407, Accuracy: 87.50%\nEpoch [1/3], Step [700/762], Loss: 0.2589, Accuracy: 100.00%\nEpoch [1/3], Step [750/762], Loss: 0.3670, Accuracy: 87.50%\nEpoch [2/3], Step [50/762], Loss: 0.1740, Accuracy: 87.50%\nEpoch [2/3], Step [100/762], Loss: 0.0909, Accuracy: 100.00%\nEpoch [2/3], Step [150/762], Loss: 0.2027, Accuracy: 100.00%\nEpoch [2/3], Step [200/762], Loss: 0.6361, Accuracy: 75.00%\nEpoch [2/3], Step [250/762], Loss: 0.3925, Accuracy: 87.50%\nEpoch [2/3], Step [300/762], Loss: 0.4011, Accuracy: 87.50%\nEpoch [2/3], Step [350/762], Loss: 0.2706, Accuracy: 87.50%\nEpoch [2/3], Step [400/762], Loss: 0.1579, Accuracy: 87.50%\nEpoch [2/3], Step [450/762], Loss: 0.6335, Accuracy: 75.00%\nEpoch [2/3], Step [500/762], Loss: 0.3768, Accuracy: 87.50%\nEpoch [2/3], Step [550/762], Loss: 0.1948, Accuracy: 100.00%\nEpoch [2/3], Step [600/762], Loss: 0.3049, Accuracy: 87.50%\nEpoch [2/3], Step [650/762], Loss: 0.1382, Accuracy: 100.00%\nEpoch [2/3], Step [700/762], Loss: 0.0959, Accuracy: 100.00%\nEpoch [2/3], Step [750/762], Loss: 0.2435, Accuracy: 87.50%\nEpoch [3/3], Step [50/762], Loss: 0.0696, Accuracy: 100.00%\nEpoch [3/3], Step [100/762], Loss: 0.6036, Accuracy: 75.00%\nEpoch [3/3], Step [150/762], Loss: 0.1432, Accuracy: 100.00%\nEpoch [3/3], Step [200/762], Loss: 0.1671, Accuracy: 87.50%\nEpoch [3/3], Step [250/762], Loss: 0.2635, Accuracy: 87.50%\nEpoch [3/3], Step [300/762], Loss: 0.2184, Accuracy: 87.50%\nEpoch [3/3], Step [350/762], Loss: 0.5914, Accuracy: 87.50%\nEpoch [3/3], Step [400/762], Loss: 0.3815, Accuracy: 75.00%\nEpoch [3/3], Step [450/762], Loss: 0.1675, Accuracy: 87.50%\nEpoch [3/3], Step [500/762], Loss: 0.2472, Accuracy: 87.50%\nEpoch [3/3], Step [550/762], Loss: 0.1520, Accuracy: 87.50%\nEpoch [3/3], Step [600/762], Loss: 0.4035, Accuracy: 87.50%\nEpoch [3/3], Step [650/762], Loss: 0.1162, Accuracy: 100.00%\nEpoch [3/3], Step [700/762], Loss: 0.2368, Accuracy: 87.50%\nEpoch [3/3], Step [750/762], Loss: 0.0947, Accuracy: 100.00%\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:55:51,698][INFO] ## *** Example ***\n[2020-03-03 19:55:51,699][INFO] ## idx: 0\n[2020-03-03 19:55:51,700][INFO] ## id: 4\n[2020-03-03 19:55:51,703][INFO] ## tokens: [CLS] forest fire near la ron ##ge sas ##k . canada [SEP]\n[2020-03-03 19:55:51,706][INFO] ## input_ids: 101 3224 2543 2379 2474 6902 3351 21871 2243 1012 2710 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:55:51,708][INFO] ## input_mask: 512\n[2020-03-03 19:55:51,708][INFO] ## segment_ids: 512\n[2020-03-03 19:55:51,709][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Validation performance on 3-th fold: 0.4303988064339809\n","name":"stdout"},{"output_type":"stream","text":"[2020-03-03 19:55:57,507][INFO] ## *** Example ***\n[2020-03-03 19:55:57,508][INFO] ## idx: 0\n[2020-03-03 19:55:57,509][INFO] ## id: 1\n[2020-03-03 19:55:57,512][INFO] ## tokens: [CLS] our deeds are the reason of this # earthquake may allah forgive us all [SEP]\n[2020-03-03 19:55:57,514][INFO] ## input_ids: 101 2256 15616 2024 1996 3114 1997 2023 1001 8372 2089 16455 9641 2149 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[2020-03-03 19:55:57,516][INFO] ## input_mask: 512\n[2020-03-03 19:55:57,518][INFO] ## segment_ids: 512\n[2020-03-03 19:55:57,519][INFO] ## label: 1\n","name":"stderr"},{"output_type":"stream","text":"Epoch [1/3], Step [50/762], Loss: 0.8951, Accuracy: 37.50%\nEpoch [1/3], Step [100/762], Loss: 0.2706, Accuracy: 100.00%\nEpoch [1/3], Step [150/762], Loss: 0.3589, Accuracy: 87.50%\nEpoch [1/3], Step [200/762], Loss: 0.2700, Accuracy: 87.50%\nEpoch [1/3], Step [250/762], Loss: 0.6355, Accuracy: 75.00%\nEpoch [1/3], Step [300/762], Loss: 0.1280, Accuracy: 100.00%\nEpoch [1/3], Step [350/762], Loss: 0.5207, Accuracy: 75.00%\nEpoch [1/3], Step [400/762], Loss: 0.4226, Accuracy: 75.00%\nEpoch [1/3], Step [450/762], Loss: 0.2924, Accuracy: 100.00%\nEpoch [1/3], Step [500/762], Loss: 0.2254, Accuracy: 100.00%\nEpoch [1/3], Step [550/762], Loss: 0.4133, Accuracy: 87.50%\nEpoch [1/3], Step [600/762], Loss: 0.5042, Accuracy: 87.50%\nEpoch [1/3], Step [650/762], Loss: 0.4459, Accuracy: 87.50%\nEpoch [1/3], Step [700/762], Loss: 0.1088, Accuracy: 100.00%\nEpoch [1/3], Step [750/762], Loss: 0.7340, Accuracy: 75.00%\nEpoch [2/3], Step [50/762], Loss: 0.1631, Accuracy: 100.00%\nEpoch [2/3], Step [100/762], Loss: 0.1505, Accuracy: 100.00%\nEpoch [2/3], Step [150/762], Loss: 1.0113, Accuracy: 62.50%\nEpoch [2/3], Step [200/762], Loss: 0.1051, Accuracy: 100.00%\nEpoch [2/3], Step [250/762], Loss: 0.5842, Accuracy: 75.00%\nEpoch [2/3], Step [300/762], Loss: 0.4380, Accuracy: 62.50%\nEpoch [2/3], Step [350/762], Loss: 0.1133, Accuracy: 100.00%\nEpoch [2/3], Step [400/762], Loss: 0.6969, Accuracy: 62.50%\nEpoch [2/3], Step [450/762], Loss: 0.2065, Accuracy: 100.00%\nEpoch [2/3], Step [500/762], Loss: 0.4103, Accuracy: 75.00%\nEpoch [2/3], Step [550/762], Loss: 0.4659, Accuracy: 75.00%\nEpoch [2/3], Step [600/762], Loss: 0.9925, Accuracy: 62.50%\nEpoch [2/3], Step [650/762], Loss: 0.9969, Accuracy: 62.50%\nEpoch [2/3], Step [700/762], Loss: 0.2272, Accuracy: 87.50%\nEpoch [2/3], Step [750/762], Loss: 0.4496, Accuracy: 75.00%\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-7351ecaa09b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"<h2>Inference</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_examples, test_df = read_examples(test_df, is_training=False)\ntest_features = convert_examples_to_features(test_examples, tokenizer, MAX_SEQ_LENGTH, True)\ntest_input_ids = torch.tensor(select_field(test_features, 'input_ids'), dtype=torch.long)\ntest_input_mask = torch.tensor(select_field(test_features, 'input_mask'), dtype=torch.long)\ntest_segment_ids = torch.tensor(select_field(test_features, 'segment_ids'), dtype=torch.long)\n\ntest = torch.utils.data.TensorDataset(test_input_ids, test_input_mask, test_segment_ids)\n\ntest_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting with 5 models\n\npreds = []\n\nfor i, model in enumerate(models):\n    \n    test_preds = []\n    \n    model.eval()\n\n    with torch.no_grad():\n            for i, batch in enumerate(test_loader):\n                batch = tuple(t.cuda() for t in batch)\n                x_ids, x_mask, x_sids = batch\n                y_pred = model(x_ids, x_mask, x_sids).detach()\n                test_preds[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] = F.softmax(y_pred, dim=1).cpu().numpy()  \n    \n    print(\"MODEL {}: inference done\".format(i))\n    \n    preds.append(test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = np.mean(preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Averaging predictions\nfinal_preds = np.argmax(mean, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample['target'] = final_preds\n#sample.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/output/working')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}